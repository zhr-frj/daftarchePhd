{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhr-frj/daftarchePhd/blob/main/Copy_of_Untitled0LaBSEGemma9B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W0CPCljcr5F",
        "outputId": "df08b1d5-60ac-4bf5-c811-6787d976f525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 14 21:28:21 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPWK7nYxcGPx",
        "outputId": "5015b04a-0bf1-4022-c02c-6cb5445ad7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ø¯Ø± Ø­Ø§Ù„ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ ---\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m--- Ù†ØµØ¨ Ú©Ø§Ù…Ù„ Ø´Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "# --- Ù†ØµØ¨ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ùˆ Ù¾Ø§ÛŒØ¯Ø§Ø± ---\n",
        "print(\"--- Ø¯Ø± Ø­Ø§Ù„ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ ---\")\n",
        "!pip install langchain langchain-community transformers bitsandbytes accelerate faiss-cpu pypdf sentence-transformers langchain_huggingface docarray -q\n",
        "print(\"--- Ù†ØµØ¨ Ú©Ø§Ù…Ù„ Ø´Ø¯ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iUDnauFYxFq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a7ae77-866b-4534-a210-d2efa83c10e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ (Quantization) ---\n",
            "--- Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "#  --- ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ---\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "print(\"--- Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ (Quantization) ---\")\n",
        "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ 4-bit Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=\"float16\",\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "print(\"--- Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZrAJvITztf9",
        "outputId": "39806a0d-05e5-408e-a444-000044eed2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ù…ØªØ±Ø¬Ù…Â» (Tokenizer) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e41e45738f8e43f4b68e82cdd4a65c49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26c41357cf594819b933e5e05b52b371"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d11b090d940b418f9e5e306523b7bfaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f343a32d732846ea8459e65fcf05c0d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Â«Ù…ØªØ±Ø¬Ù…Â» (Tokenizer) Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ù…ØªØ±Ø¬Ù…Â» (Tokenizer) - Gemma 9B ---\n",
        "from transformers import AutoTokenizer\n",
        "# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ù…ØªØ±Ø¬Ù…Â» (Tokenizer) ---\n",
        "print(\"--- Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ù…ØªØ±Ø¬Ù…Â» (Tokenizer) ---\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/gemma-2-9b-it\", use_fast=True)\n",
        "print(\"--- Â«Ù…ØªØ±Ø¬Ù…Â» (Tokenizer) Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TihILDUIzx7o",
        "outputId": "e65600f2-e0f7-4e0f-fe44-1c82e93d0481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ù…ØºØ²Â» (LLM) --- (Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø³ÛŒØ§Ø± Ø³Ù†Ú¯ÛŒÙ† Ùˆ Ø²Ù…Ø§Ù†â€ŒØ¨Ø± Ø§Ø³Øª)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/927 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6475e9ca351e47059a9ab22838b6b008"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "936af88984934a029e32017edcd9377c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d6a89cfe8734d18aeaa820f79c40c8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5db1eb548eb9492ba29d38242f9cd32f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9acbe306cf14f73bcb258150efb13d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cb018c3283d43ceab399ffb69586791"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b5bd93ea65345afab3f59eda36b57a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cee60f34be7f403bacc7208ca11f411e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bb8a74e476d4d4e9a4329c0e56201b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Â«Ù…ØºØ²Â» (LLM) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ù…ØºØ²Â» (LLM) ---\n",
        "\n",
        "from transformers import AutoModelForCausalLM\n",
        "print(\"--- Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ù…ØºØ²Â» (LLM) --- (Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø³ÛŒØ§Ø± Ø³Ù†Ú¯ÛŒÙ† Ùˆ Ø²Ù…Ø§Ù†â€ŒØ¨Ø± Ø§Ø³Øª)\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"unsloth/gemma-2-9b-it\",\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "print(\"--- Â«Ù…ØºØ²Â» (LLM) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aXgzl26z5Br",
        "outputId": "20d771a2-fce8-454e-e62d-719599ed0319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Â«Ø®Ø· Ù„ÙˆÙ„Ù‡Â» (Pipeline) ---\n",
            "--- Â«Ø®Ø· Ù„ÙˆÙ„Ù‡Â»ØŒ Â«ØºÙ„Ø§ÙÂ» Ùˆ Â«ØªÙ…ÛŒØ²Ú©Ù†Ù†Ø¯Ù‡Â» (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ) Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "# --- (Ù†Ù‡Ø§ÛŒÛŒ): Ø³Ø§Ø®Øª Â«Ø®Ø· Ù„ÙˆÙ„Ù‡Â» (Pipeline) Ùˆ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ LangChain ---\n",
        "print(\"--- Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Â«Ø®Ø· Ù„ÙˆÙ„Ù‡Â» (Pipeline) ---\")\n",
        "\n",
        "text_gen_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,  # Ø§ÙØ²Ø§ÛŒØ´ Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø®\n",
        "    return_full_text=False # --- ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ: ÙÙ‚Ø· Ø¬ÙˆØ§Ø¨ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ØŒ Ù†Ù‡ Ù¾Ø±Ø§Ù…Ù¾Øª Ø±Ø§ ---\n",
        ")\n",
        "\n",
        "# Ø³Ø§Ø®Øª Â«ØºÙ„Ø§ÙÂ» LangChain Ø¨Ø±Ø§ÛŒ LLM\n",
        "llm = HuggingFacePipeline(pipeline=text_gen_pipeline)\n",
        "\n",
        "# Ø³Ø§Ø®Øª Â«ØªÙ…ÛŒØ²Ú©Ù†Ù†Ø¯Ù‡ Ø®Ø±ÙˆØ¬ÛŒÂ»\n",
        "parser = StrOutputParser()\n",
        "\n",
        "print(\"--- Â«Ø®Ø· Ù„ÙˆÙ„Ù‡Â»ØŒ Â«ØºÙ„Ø§ÙÂ» Ùˆ Â«ØªÙ…ÛŒØ²Ú©Ù†Ù†Ø¯Ù‡Â» (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ) Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-oLghHF0WSw",
        "outputId": "443191e4-9757-4978-a9f5-072d7a0b5774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ø¨ÛŒÙ†ÛŒ Ù…Ø¹Ù†ÛŒâ€ŒÙÙ‡Ù…Â» (Embeddings) - Ù†Ø³Ø®Ù‡ Ù‚ÙˆÛŒ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ (LaBSE) ---\n",
            "--- Â«Ø¨ÛŒÙ†ÛŒ Ù…Ø¹Ù†ÛŒâ€ŒÙÙ‡Ù…Â» (Embeddings) Ø¬Ø¯ÛŒØ¯ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ø¨ÛŒÙ†ÛŒ Ù…Ø¹Ù†ÛŒâ€ŒÙÙ‡Ù…Â» (Embedding Model) - Ù†Ø³Ø®Ù‡ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ LaBSE ---\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "print(\"--- Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ø¨ÛŒÙ†ÛŒ Ù…Ø¹Ù†ÛŒâ€ŒÙÙ‡Ù…Â» (Embeddings) - Ù†Ø³Ø®Ù‡ Ù‚ÙˆÛŒ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ (LaBSE) ---\")\n",
        "\n",
        "# --- ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ---\n",
        "# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ùˆ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ LaBSE\n",
        "embedding_name = 'sentence-transformers/LaBSE'\n",
        "# --- Ù¾Ø§ÛŒØ§Ù† ØªØºÛŒÛŒØ± ---\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=embedding_name,\n",
        "    model_kwargs={'device': 'cpu'} # Ù‡Ù…Ú†Ù†Ø§Ù† Ø±ÙˆÛŒ CPU Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ GPU Ø¢Ø²Ø§Ø¯ Ø¨Ù…Ø§Ù†Ø¯\n",
        ")\n",
        "print(\"--- Â«Ø¨ÛŒÙ†ÛŒ Ù…Ø¹Ù†ÛŒâ€ŒÙÙ‡Ù…Â» (Embeddings) Ø¬Ø¯ÛŒØ¯ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMM1J-0N0hCQ",
        "outputId": "c26d8807-38e5-4eca-bc05-3a3ab829b672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ ØªØ¹Ø±ÛŒÙ Â«Ù‚Ø§Ù„Ø¨ Ú†ØªÂ» (ChatPromptTemplate) - Ù†Ø³Ø®Ù‡ ØªØ±Ú©ÛŒØ¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ ---\n",
            "--- âœ… Â«Ù‚Ø§Ù„Ø¨ Ú†ØªÂ» (Prompt) ØªØ±Ú©ÛŒØ¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "# --- ØªØ¹Ø±ÛŒÙ Â«Ù‚Ø§Ù„Ø¨ Ú†ØªÂ» (ChatPromptTemplate) - Ù†Ø³Ø®Ù‡ ØªØ±Ú©ÛŒØ¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ ---\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "print(\"--- ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ ØªØ¹Ø±ÛŒÙ Â«Ù‚Ø§Ù„Ø¨ Ú†ØªÂ» (ChatPromptTemplate) - Ù†Ø³Ø®Ù‡ ØªØ±Ú©ÛŒØ¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ ---\")\n",
        "\n",
        "# --- ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ---\n",
        "# Ù…Ø§ Ù‡Ø± Ø¯Ùˆ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„ Ù…ÙˆÙÙ‚ Ø±Ø§ ØªØ±Ú©ÛŒØ¨ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:\n",
        "# Û±. Ø¯Ø³ØªÙˆØ± Â«Ú¯Ø±Ø¯Ø¢ÙˆØ±ÛŒÂ» (Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„ Ø³Ù‡Ù…ÛŒÙ‡)\n",
        "# Û². Ø¯Ø³ØªÙˆØ± Â«Ø¯Ù‚Øª Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø±Â» (Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ)\n",
        "SYSTEM_TEMPLATE = \"\"\"\n",
        "Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ØŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ù…ÙÛŒØ¯ Ù‡Ø³ØªÛŒØ¯.\n",
        "ÙˆØ¸ÛŒÙÙ‡ Ø´Ù…Ø§ Ù¾Ø§Ø³Ø® Ø¨Ù‡ Â«Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±Â» Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Â«Ø²Ù…ÛŒÙ†Ù‡Â» Ø§Ø³Øª.\n",
        "\n",
        "*Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ:*\n",
        "Û±. *Ú¯Ø±Ø¯Ø¢ÙˆØ±ÛŒ Ú©Ø§Ù…Ù„ (Synthesize):* Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ *Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ú©Ø§Ù…Ù„* Ø§Ø² *ØªÙ…Ø§Ù…* Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·ÛŒ Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø¯Ø± Â«Ø²Ù…ÛŒÙ†Ù‡Â» Ø¯Ø± Ù…ÙˆØ±Ø¯ Â«Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±Â» Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯. (Ù…Ø«Ù„Ø§Ù‹ Ø§Ú¯Ø± Ø¯Ùˆ Ø³Ù‡Ù…ÛŒÙ‡ Ù…Ø®ØªÙ„Ù Ø°Ú©Ø± Ø´Ø¯Ù‡ØŒ Ù‡Ø± Ø¯Ùˆ Ø±Ø§ Ø¨ÛŒØ§ÙˆØ±ÛŒØ¯).\n",
        "Û². *Ø¯Ù‚Øª Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø± (Structure-Aware):* Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø± Ù…ØªÙ†ØŒ Ø¬Ø¯Ø§ÙˆÙ„ØŒ Ø³Ø±ÙØµÙ„â€ŒÙ‡Ø§ Ùˆ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ Ø¯Ù‚Øª Ú©Ù†ÛŒØ¯. Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ø§ Ø§Ø² Ø¨Ø®Ø´ Ø¯Ø±Ø³ØªÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ (Ù…Ø«Ù„Ø§Ù‹ Â«Ú¯Ø±Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ø±Ø´ØªÙ‡Â» Ø±Ø§ Ø¨Ø§ Â«Ø¯Ø±ÙˆØ³ Ø§Ù…ØªØ­Ø§Ù†ÛŒÂ» ÛŒØ§ Â«Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·Â» Ø§Ø´ØªØ¨Ø§Ù‡ Ù†Ú¯ÛŒØ±ÛŒØ¯).\n",
        "Û³. *Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ† Ù†ÙˆÛŒØ²:* Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ú©Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡ Â«Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±Â» Ù…Ø±Ø¨ÙˆØ· Ù†ÛŒØ³ØªÙ†Ø¯ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±ÛŒØ¯.\n",
        "Û´. *Ù¾Ø§ÛŒØ¨Ù†Ø¯ÛŒ:* Ø§Ú¯Ø± Ù¾Ø§Ø³Ø® Ø³ÙˆØ§Ù„ Ø¨Ù‡ Ù‡ÛŒÚ† ÙˆØ¬Ù‡ Ø¯Ø± Â«Ø²Ù…ÛŒÙ†Ù‡Â» ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø¨Ú¯ÙˆÛŒÛŒØ¯: \"Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ±Ø¯ Ø¯Ø± Ø§Ø³Ù†Ø§Ø¯ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù….\"\n",
        "\"\"\"\n",
        "\n",
        "# Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø± Ùˆ Ø²Ù…ÛŒÙ†Ù‡ Ø¯Ø± Ù‚Ø§Ù„Ø¨ Â«Ø§Ù†Ø³Ø§Ù†Â» Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯\n",
        "HUMAN_TEMPLATE = \"\"\"\n",
        "Ø²Ù…ÛŒÙ†Ù‡ (Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØªâ€ŒØ´Ø¯Ù‡ Ø§Ø² PDF):\n",
        "{context}\n",
        "---\n",
        "Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±:\n",
        "{question}\n",
        "---\n",
        "Ù¾Ø§Ø³Ø® Ø¯Ù‚ÛŒÙ‚ Ùˆ Ú©Ø§Ù…Ù„ Ø´Ù…Ø§ (ÙÙ‚Ø· Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ):\n",
        "\"\"\"\n",
        "\n",
        "# Ø³Ø§Ø®Øª Ù‚Ø§Ù„Ø¨ Ú†Øª Ù†Ù‡Ø§ÛŒÛŒ\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", SYSTEM_TEMPLATE),\n",
        "    (\"human\", HUMAN_TEMPLATE),\n",
        "])\n",
        "\n",
        "print(\"--- âœ… Â«Ù‚Ø§Ù„Ø¨ Ú†ØªÂ» (Prompt) ØªØ±Ú©ÛŒØ¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWOmShtw0iBv",
        "outputId": "bc0d362f-5f4a-495b-c0c4-a052857814f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ PDF ---\n",
            "--- ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "# --- Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ PDF ---\n",
        "print(\"--- Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ PDF ---\")\n",
        "!wget -q \"https://github.com/zhr-frj/daftarchePhd/releases/download/v1.0.0/Phd1405-.konkur.in.pdf\" -O daftarche_asli.pdf\n",
        "!wget -q \"https://github.com/zhr-frj/daftarchePhd/releases/download/v1.0.0/Eslahiye-PHD1405-.konkur.in.pdf\" -O daftarche_eslahiye.pdf\n",
        "print(\"--- ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97d3gHt71QfS",
        "outputId": "ff8cb105-3683-4e6f-b980-c5e2503c1fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ PDF\n",
            "--- Ù…Ø¬Ù…ÙˆØ¹Ø§ 58 ØµÙØ­Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ ---\n",
            "... Ø¯Ø± Ø­Ø§Ù„ Ø®ÙØ±Ø¯ Ú©Ø±Ø¯Ù† Ù…ØªÙ†â€ŒÙ‡Ø§\n",
            "--- Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ 394 ØªÚ©Ù‡ (Chunk) ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯Ù†Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "# --- Ø®ÙˆØ§Ù†Ø¯Ù†ØŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø®ÙØ±Ø¯ Ú©Ø±Ø¯Ù† Ù…ØªÙ†â€ŒÙ‡Ø§ ---\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Û±. Ø®ÙˆØ§Ù†Ø¯Ù† Ù‡Ø± Ø¯Ùˆ ÙØ§ÛŒÙ„ PDF\n",
        "print(\"... Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ PDF\")\n",
        "loader_asli = PyPDFLoader(\"daftarche_asli.pdf\")\n",
        "loader_eslahiye = PyPDFLoader(\"daftarche_eslahiye.pdf\")\n",
        "all_pages = loader_asli.load() + loader_eslahiye.load()\n",
        "print(f\"--- Ù…Ø¬Ù…ÙˆØ¹Ø§ {len(all_pages)} ØµÙØ­Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ ---\")\n",
        "\n",
        "# Û². Ø®ÙØ±Ø¯ Ú©Ø±Ø¯Ù† Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ ØªÚ©Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú© (Chunks)\n",
        "print(\"... Ø¯Ø± Ø­Ø§Ù„ Ø®ÙØ±Ø¯ Ú©Ø±Ø¯Ù† Ù…ØªÙ†â€ŒÙ‡Ø§\")\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=128)\n",
        "text_documents = text_splitter.split_documents(all_pages)\n",
        "print(f\"--- Ù…ØªÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ {len(text_documents)} ØªÚ©Ù‡ (Chunk) ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯Ù†Ø¯ ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKEaDg631UKF",
        "outputId": "d4d3bd60-2105-4fea-fa46-5767a3dfc1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ğŸ’¾ Ù†Ø§Ù… Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯: faiss_index_daftarche_labse ---\n",
            "--- Â«Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Â» (faiss_index_daftarche_labse) Ø§Ø² Ù‚Ø¨Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³Ø±ÛŒØ¹ Ø§Ø² Ø¯ÛŒØ³Ú©...\n",
            "--- Â«Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Â» Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ ---\n"
          ]
        }
      ],
      "source": [
        "# --- Ø³Ø§Ø®Øª ÛŒØ§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Â«Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Â» (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø§ÛŒÙ…Ù†) ---\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import os\n",
        "\n",
        "# --- ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ: Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø­Ø§Ù„Ø§ Ø´Ø§Ù…Ù„ Ù†Ø§Ù… Ù…Ø¯Ù„ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ Ø§Ø³Øª ---\n",
        "DB_FAISS_PATH = \"faiss_index_daftarche_labse\"\n",
        "print(f\"--- ğŸ’¾ Ù†Ø§Ù… Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯: {DB_FAISS_PATH} ---\")\n",
        "\n",
        "# --- Ø­Ø°Ù Ø¯Ø³ØªÙˆØ± !rm -rf : Ù…Ø§ Ø¯ÛŒÚ¯Ø± ÙØ§ÛŒÙ„ Ø±Ø§ Ø¨Ù‡ Ø²ÙˆØ± Ù¾Ø§Ú© Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ---\n",
        "\n",
        "if not os.path.exists(DB_FAISS_PATH):\n",
        "    print(f\"... Â«Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Â» ({DB_FAISS_PATH}) ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Ø¨Ø§ Ù…Ø¯Ù„ (LaBSE)...\")\n",
        "\n",
        "    vectorstore = FAISS.from_documents(\n",
        "        text_documents,\n",
        "        embedding=embeddings # Ø§Ø² Ù…ØªØºÛŒØ± embeddings (Ø¬Ø¯ÛŒØ¯ LaBSE) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\n",
        "    )\n",
        "\n",
        "    print(\"... Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ø±ÙˆÛŒ Ø¯ÛŒØ³Ú© ...\")\n",
        "    vectorstore.save_local(DB_FAISS_PATH)\n",
        "    print(f\"--- Â«Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Â» Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ùˆ Ø¯Ø± {DB_FAISS_PATH} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ ---\")\n",
        "\n",
        "else:\n",
        "    print(f\"--- Â«Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Â» ({DB_FAISS_PATH}) Ø§Ø² Ù‚Ø¨Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³Ø±ÛŒØ¹ Ø§Ø² Ø¯ÛŒØ³Ú©...\")\n",
        "    vectorstore = FAISS.load_local(\n",
        "        DB_FAISS_PATH,\n",
        "        embeddings, # Ù…Ø¯Ù„ Ø§Ù…Ø¨Ø¯ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª\n",
        "        allow_dangerous_deserialization=True # Ø¨Ø±Ø§ÛŒ FAISS Ø¯Ø± LangChain Ù„Ø§Ø²Ù… Ø§Ø³Øª\n",
        "    )\n",
        "    print(\"--- Â«Ø¨Ø§ÛŒÚ¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Â» Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ ---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- (Ø¨): Ø³Ø§Ø®Øª Â«Ú©ØªØ§Ø¨Ø¯Ø§Ø±Â» (Retriever) - Ø¨Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Similarity ---\n",
        "\n",
        "# --- ØªØºÛŒÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ---\n",
        "# Ù…Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ \"mmr\" Ø±Ø§ Ø­Ø°Ù Ú©Ø±Ø¯ÛŒÙ… Ùˆ Ø¨Ù‡ Ø­Ø§Ù„Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ (similarity) Ø¨Ø±Ú¯Ø´ØªÛŒÙ….\n",
        "# Ù…Ø§ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¯Ø§Ø±ÛŒÙ… Ú©Ù‡ \"Ø¨ÛŒÙ†ÛŒ Ù…Ø¹Ù†ÛŒâ€ŒÙÙ‡Ù…\" LaBSE Ø¢Ù†Ù‚Ø¯Ø± Ù‚ÙˆÛŒ Ø§Ø³Øª\n",
        "# Ú©Ù‡ Ø¯Ø± Ø­Ø§Ù„Øª similarity Ù‡Ù… Ù†ØªØ§ÛŒØ¬ Ø®ÙˆØ¨ÛŒ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯.\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={'k': 5} # Ûµ Ù†ØªÛŒØ¬Ù‡ Ø¨Ø±ØªØ± Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ø¨Ø§Ù‡Øª\n",
        ")\n",
        "\n",
        "print(\"--- Â«Ú©ØªØ§Ø¨Ø¯Ø§Ø±Â» (Retriever) Ø¨Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Similarity (Ù¾ÛŒØ´â€ŒÙØ±Ø¶) Ø¢Ù…Ø§Ø¯Ù‡ Ø¬Ø³ØªØ¬Ùˆ Ø§Ø³Øª ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWAdy8JlFodx",
        "outputId": "079f294e-1c9b-4919-f0be-b1fdca6512bc"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Â«Ú©ØªØ§Ø¨Ø¯Ø§Ø±Â» (Retriever) Ø¨Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Similarity (Ù¾ÛŒØ´â€ŒÙØ±Ø¶) Ø¢Ù…Ø§Ø¯Ù‡ Ø¬Ø³ØªØ¬Ùˆ Ø§Ø³Øª ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- (Ø¬Ø¯ÛŒØ¯): Ø³Ø§Ø®Øª Ø²Ù†Ø¬ÛŒØ±Ù‡ RAG Ø¨Ø§ LCEL ---\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "print(\"--- ğŸ§  Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Ø²Ù†Ø¬ÛŒØ±Ù‡ RAG (RAG Chain) Ù…Ø¯Ø±Ù† Ø¨Ø§ LCEL ---\")\n",
        "\n",
        "# Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø§Ø³Ù†Ø§Ø¯ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ù…ØªÙ† ÙˆØ§Ø­Ø¯ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# --- Ø³Ø§Ø®Øª Ø²Ù†Ø¬ÛŒØ±Ù‡ (Chain) Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² LCEL (Ø²Ø¨Ø§Ù† Ø¹Ø¨Ø§Ø±ØªÛŒ LangChain) ---\n",
        "# Ø§ÛŒÙ† Ø²Ù†Ø¬ÛŒØ±Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø±ØŒ Ø§ÛŒÙ…Ù† Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ ØªÙ…Ø§Ù… Ù…Ø±Ø§Ø­Ù„ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡Ø¯:\n",
        "# 1. Ø³ÙˆØ§Ù„ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ (RunnablePassthrough)\n",
        "# 2. Ø¨Ù‡ Ú©ØªØ§Ø¨Ø¯Ø§Ø± (retriever) Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ùˆ Ø§Ø³Ù†Ø§Ø¯ Ø±Ø§ ÙØ±Ù…Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (format_docs)\n",
        "# 3. Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ {context, question} Ø±Ø§ Ø¨Ù‡ Ù¾Ø±Ø§Ù…Ù¾Øª Ù…ÛŒâ€ŒØ¯Ù‡Ø¯\n",
        "# 4. Ø®Ø±ÙˆØ¬ÛŒ Ù¾Ø±Ø§Ù…Ù¾Øª Ø±Ø§ Ø¨Ù‡ Â«Ù…ØºØ²Â» (llm) Ù…ÛŒâ€ŒØ¯Ù‡Ø¯\n",
        "# 5. Ø®Ø±ÙˆØ¬ÛŒ Â«Ù…ØºØ²Â» Ø±Ø§ Ø¨Ù‡ Â«ØªÙ…ÛŒØ²Ú©Ù†Ù†Ø¯Ù‡Â» (StrOutputParser) Ù…ÛŒâ€ŒØ¯Ù‡Ø¯\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt  # Ù¾Ø±Ø§Ù…Ù¾Øª Â«Ø³Ø®Øªâ€ŒÚ¯ÛŒØ±Ø§Ù†Ù‡Â» Ú©Ù‡ Ø¯Ø± Ø³Ù„ÙˆÙ„ Ûµ Ø³Ø§Ø®ØªÛŒÙ…\n",
        "    | llm     # Ù…Ø¯Ù„ gemma-9b\n",
        "    | StrOutputParser() # Ù¾Ø§Ø±Ø³Ø± Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¯Ø± Ø²Ù†Ø¬ÛŒØ±Ù‡ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…\n",
        ")\n",
        "\n",
        "print(\"--- âœ… Ø²Ù†Ø¬ÛŒØ±Ù‡ RAG Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erjq7C4b1EO0",
        "outputId": "b4852552-a224-4d58-ed68-c30768f227de"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ğŸ§  Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Ø²Ù†Ø¬ÛŒØ±Ù‡ RAG (RAG Chain) Ù…Ø¯Ø±Ù† Ø¨Ø§ LCEL ---\n",
            "--- âœ… Ø²Ù†Ø¬ÛŒØ±Ù‡ RAG Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- : ØªØ¹Ø±ÛŒÙ ØªØ§Ø¨Ø¹ 'ask_robot' (Ù†Ø³Ø®Ù‡ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡) ---\n",
        "\n",
        "print(\"--- ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ ØªØ¹Ø±ÛŒÙ ØªØ§Ø¨Ø¹ 'ask_robot' (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ) ---\")\n",
        "\n",
        "def ask_robot(question):\n",
        "    \"\"\"\n",
        "    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ ÛŒÚ© Ø³ÙˆØ§Ù„ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ Ùˆ Ø¢Ù† Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø¨Ù‡ Ø²Ù†Ø¬ÛŒØ±Ù‡ RAG Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.\n",
        "    (Ø¨Ø¯ÙˆÙ† Ù‡ÛŒÚ† Ù¾Ø±ÛŒÙ†Øª Ø§Ø¶Ø§ÙÛŒ)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ú©Ù„ Ø²Ù†Ø¬ÛŒØ±Ù‡ RAG ---\n",
        "        # ØªÙ…Ø§Ù… print Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¯ÛŒØ¨Ø§Ú¯ Ø­Ø°Ù Ø´Ø¯Ù†Ø¯.\n",
        "        response = rag_chain.invoke(question)\n",
        "\n",
        "        return response.strip() # ÙÙ‚Ø· Ø¬ÙˆØ§Ø¨ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ØªÙ…ÛŒØ² Ø´Ø¯Ù‡\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø® Ø¯Ø§Ø¯: {e}\"\n",
        "\n",
        "print(\"--- âœ… ØªØ§Ø¨Ø¹ 'ask_robot' (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5JGeRh_1Fl-",
        "outputId": "f5739fc1-c008-4cc3-bd10-c0898f0d246b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ ØªØ¹Ø±ÛŒÙ ØªØ§Ø¨Ø¹ 'ask_robot' (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ) ---\n",
            "--- âœ… ØªØ§Ø¨Ø¹ 'ask_robot' (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0c8g3f02QO3",
        "outputId": "efd5f960-18c3-4562-8ba1-dc90ac5b0734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ğŸ¤– Ø´Ø±ÙˆØ¹ ØªØ³Øª Ø±Ø¨Ø§Øª Ø¨Ø§ Ø³ÙˆØ§Ù„Ø§Øª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ğŸ¤– ---\n",
            "[Ø´Ù…Ø§]: Ø³Ù‡Ù…ÛŒÙ‡ Ø§ÛŒØ«Ø§Ø±Ú¯Ø±Ø§Ù† Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ø³Ù‡Ù…ÛŒÙ‡ Ø§ÛŒØ«Ø§Ø±Ú¯Ø±Ø§Ù† Ø¯Ø± Ù‡Ø± Ú©Ø¯Ø±Ø´ØªÙ‡Ù…Ø­Ù„ Ø¨Ù‡ Ø¯Ùˆ ØµÙˆØ±Øª Ø§Ø³Øª:\n",
            "\n",
            "1. 25% Ø§Ø² Ø¸Ø±ÙÛŒØª Ù‡Ø± Ú©Ø¯Ø±Ø´ØªÙ‡Ù…Ø­Ù„ Ø¨Ù‡ \"Ù‡Ù…Ø³Ø± Ùˆ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø´Ù‡Ø¯Ø§ Ùˆ Ù…ÙÙ‚ÙˆØ¯Ø§Ù„Ø§Ø«Ø±Ø§Ù†\"ØŒ \"Ø¢Ø²Ø§Ø¯Ú¯Ø§Ù† Ùˆ Ù‡Ù…Ø³Ø± Ùˆ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¢Ù†Ø§Ù†\" Ùˆ \"Ø¬Ø§Ù†Ø¨Ø§Ø²Ø§Ù† 52% Ùˆ Ø¨Ø§Ù„Ø§ØªØ± Ùˆ Ù‡Ù…Ø³Ø± Ùˆ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¢Ù†Ø§Ù†\" Ø§Ø®ØªØµØ§Øµ Ø¯Ø§Ø±Ø¯.\n",
            "\n",
            "2. 5% Ø§Ø² Ø¸Ø±ÙÛŒØª Ù‡Ø± Ú©Ø¯Ø±Ø´ØªÙ‡Ù…Ø­Ù„ Ø¨Ù‡ \"Ø¬Ø§Ù†Ø¨Ø§Ø²Ø§Ù† Ø²ÛŒØ± 52% Ùˆ Ù‡Ù…Ø³Ø± Ùˆ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø¢Ù†Ø§Ù†\" Ùˆ \"Ù‡Ù…Ø³Ø± Ùˆ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø±Ø²Ù…Ù†Ø¯Ú¯Ø§Ù† Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ Ø´Ø´ Ù…Ø§Ù‡ Ø­Ø¶ÙˆØ± Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡ Ø¯Ø± Ø¬Ø¨Ù‡Ù‡\" Ø§Ø®ØªØµØ§Øµ Ø¯Ø§Ø±Ø¯.\n",
            "\n",
            "==================================================\n",
            "[Ø´Ù…Ø§]: Ú¯Ø±Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø±Ø´ØªÙ‡ Ø²Ø¨Ø§Ù† Ùˆ Ø§Ø¯Ø¨ÛŒØ§Øª ÙØ§Ø±Ø³ÛŒØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ú¯Ø±Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø±Ø´ØªÙ‡ Ø²Ø¨Ø§Ù† Ùˆ Ø§Ø¯Ø¨ÛŒØ§Øª ÙØ§Ø±Ø³ÛŒ Ø¹Ø¨Ø§Ø±ØªÙ†Ø¯ Ø§Ø²:\n",
            "\n",
            "* **Ø§Ø¯Ø¨ÛŒØ§Øª Ø­Ù…Ø§Ø³ÙŠ**\n",
            "* **Ø§Ø¯Ø¨ÙŠØ§Øª Ø¹Ø±ÙØ§Ù†ÙŠ**\n",
            "* **Ø§Ø¯Ø¨ÙŠØ§Øª ØºÙ†Ø§ÙŠÙŠ**\n",
            "* **Ø¢Ù…ÙˆØ²Ø´ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÙŠ**\n",
            "\n",
            "==================================================\n",
            "[Ø´Ù…Ø§]: Ú¯Ø±Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø¹Ù„ÙˆÙ… Ø§Ù‚ØªØµØ§Ø¯ÙŠØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ú¯Ø±Ø§ÛŒØ´  Â«Ø§Ù‚ØªØµØ§Ø¯ Ø§ÛŒØ±Ø§Ù†Â»\n",
            "\n",
            "==================================================\n",
            "[Ø´Ù…Ø§]: Ù†Ù…Ø±Ù‡ Ú©Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ú†Ú¯ÙˆÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒ Ø´ÙˆØ¯ØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ±Ø¯ Ø¯Ø± Ø§Ø³Ù†Ø§Ø¯ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù….\n",
            "\n",
            "==================================================\n",
            "[Ø´Ù…Ø§]: Ø¶Ø±ÛŒØ¨ ØªØ§Ø«ÛŒØ± Ø³ÙˆØ§Ø¨Ù‚ Ø¢Ù…ÙˆØ²Ø´ÛŒØŒ Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ Ùˆ ÙÙ†Ø§ÙˆØ±ÛŒ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø§Ø³ØªØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ±Ø¯ Ø¯Ø± Ø§Ø³Ù†Ø§Ø¯ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù….\n",
            "\n",
            "==================================================\n",
            "[Ø´Ù…Ø§]: Ú©Ø¯ Ø±Ø´ØªÙ‡ Ù…Ø­Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø±Ø´ØªÙ‡ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± - Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú©Ø¯Ø§Ù…Ù†Ø¯ØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ú©Ø¯ Ø±Ø´ØªÙ‡ Ù…Ø­Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø±Ø´ØªÙ‡ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± - Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒØŒ 2354 Ùˆ 1  Ù‡Ø³ØªÙ†Ø¯.\n",
            "\n",
            "==================================================\n",
            "[Ø´Ù…Ø§]: Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ØµÙ„Ø§Ø­ÛŒÙ‡ØŒ ØªØ§Ø±ÛŒØ® Ø¯Ù‚ÛŒÙ‚ Ø¨Ø±Ø±Ø³ÛŒ Ø³ÙˆØ§Ø¨Ù‚ Ø¹Ù„Ù…ÛŒ Ùˆ Ù…ØµØ§Ø­Ø¨Ù‡ Ú†Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø³ØªØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ±Ø¯ Ø¯Ø± Ø§Ø³Ù†Ø§Ø¯ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù….\n",
            "\n",
            "==================================================\n",
            "[Ø´Ù…Ø§]: Ø§Ø³Ù… Ù…Ù† Ú†ÛŒØ³ØªØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ±Ø¯ Ø¯Ø± Ø§Ø³Ù†Ø§Ø¯ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù….\n",
            "\n",
            "==================================================\n",
            "[Ø´Ù…Ø§]: Ù¾Ø§ÛŒØªØ®Øª Ø§ÛŒØ±Ø§Ù† Ú©Ø¬Ø§Ø³ØªØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ±Ø¯ Ø¯Ø± Ø§Ø³Ù†Ø§Ø¯ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù….\n",
            "\n",
            "==================================================\n",
            "[Ø´Ù…Ø§]: Ù…Ù† ÙØ§Ø±Øºâ€ŒØ§Ù„ØªØ­ØµÛŒÙ„ Ú©Ø§Ø±Ø´Ù†Ø§Ø³ÛŒ Ø§Ø±Ø´Ø¯ Ø±Ø´ØªÙ‡ Ø­Ù‚ÙˆÙ‚ Ø§Ù‚ØªØµØ§Ø¯ÛŒ Ù‡Ø³ØªÙ…. Ø¢ÛŒØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ØµÙ„Ø§Ø­ÛŒÙ‡ØŒ Ù…Ù† Ù…Ø¬Ø§Ø² Ø¨Ù‡ Ø«Ø¨Øªâ€ŒÙ†Ø§Ù… Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø§Ù…ØªØ­Ø§Ù†ÛŒ Ø¹Ù„ÙˆÙ… Ø§Ù‚ØªØµØ§Ø¯ÛŒ (Ú©Ø¯ Û²Û±Û±Û²) Ù‡Ø³ØªÙ…ØŸ\n",
            "\n",
            "[Ø±Ø¨Ø§Øª]:\n",
            "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¯Ø± Ø§ÛŒÙ† Ù…ÙˆØ±Ø¯ Ø¯Ø± Ø§Ø³Ù†Ø§Ø¯ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù….\n",
            "--- ğŸ ØªØ³Øª Ø±Ø¨Ø§Øª ØªÙ…Ø§Ù… Ø´Ø¯ ğŸ ---\n"
          ]
        }
      ],
      "source": [
        "# --- (Ø³ÙˆØ§Ù„ Ù†Ù‡Ø§ÛŒÛŒ): Ø§Ø¬Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø³ÙˆØ§Ù„Ø§Øª ØªØ³ØªÛŒ Ùˆ ÙÙ†ÛŒ ---\n",
        "\n",
        "print(\"--- ğŸ¤– Ø´Ø±ÙˆØ¹ ØªØ³Øª Ø±Ø¨Ø§Øª Ø¨Ø§ Ø³ÙˆØ§Ù„Ø§Øª Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ğŸ¤– ---\")\n",
        "\n",
        "# --- Ø¯Ø³ØªÙ‡ Û±: Ø³ÙˆØ§Ù„Ø§Øª Ø§ØµÙ„ÛŒ Ø´Ù…Ø§ ---\n",
        "\n",
        "query_1 = \"Ø³Ù‡Ù…ÛŒÙ‡ Ø§ÛŒØ«Ø§Ø±Ú¯Ø±Ø§Ù† Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ\"\n",
        "print(f\"[Ø´Ù…Ø§]: {query_1}\")\n",
        "answer_1 = ask_robot(query_1)\n",
        "print(f\"\\n[Ø±Ø¨Ø§Øª]:\\n{answer_1}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "query_2 = \"Ú¯Ø±Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø±Ø´ØªÙ‡ Ø²Ø¨Ø§Ù† Ùˆ Ø§Ø¯Ø¨ÛŒØ§Øª ÙØ§Ø±Ø³ÛŒØŸ\"\n",
        "print(f\"[Ø´Ù…Ø§]: {query_2}\")\n",
        "answer_2 = ask_robot(query_2)\n",
        "print(f\"\\n[Ø±Ø¨Ø§Øª]:\\n{answer_2}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "query_3 = \"Ú¯Ø±Ø§ÛŒØ´ Ù‡Ø§ÛŒ Ø¹Ù„ÙˆÙ… Ø§Ù‚ØªØµØ§Ø¯ÙŠØŸ\"\n",
        "print(f\"[Ø´Ù…Ø§]: {query_3}\")\n",
        "answer_3 = ask_robot(query_3)\n",
        "print(f\"\\n[Ø±Ø¨Ø§Øª]:\\n{answer_3}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# --- Ø¯Ø³ØªÙ‡ Û²: Ø³ÙˆØ§Ù„Ø§Øª ÙÙ†ÛŒ Ùˆ Ø¯Ù‚ÛŒÙ‚ (Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù‚Ø¯Ø±Øª Ø¬Ø³ØªØ¬Ùˆ) ---\n",
        "\n",
        "query_4 = \"Ù†Ù…Ø±Ù‡ Ú©Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ú†Ú¯ÙˆÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒ Ø´ÙˆØ¯ØŸ\"\n",
        "print(f\"[Ø´Ù…Ø§]: {query_4}\")\n",
        "answer_4 = ask_robot(query_4)\n",
        "print(f\"\\n[Ø±Ø¨Ø§Øª]:\\n{answer_4}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "query_5 = \"Ø¶Ø±ÛŒØ¨ ØªØ§Ø«ÛŒØ± Ø³ÙˆØ§Ø¨Ù‚ Ø¢Ù…ÙˆØ²Ø´ÛŒØŒ Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ Ùˆ ÙÙ†Ø§ÙˆØ±ÛŒ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø§Ø³ØªØŸ\"\n",
        "print(f\"[Ø´Ù…Ø§]: {query_5}\")\n",
        "answer_5 = ask_robot(query_5)\n",
        "print(f\"\\n[Ø±Ø¨Ø§Øª]:\\n{answer_5}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# --- Ø¯Ø³ØªÙ‡ Û³: Ø³ÙˆØ§Ù„Ø§Øª ØªØ±Ú©ÛŒØ¨ÛŒ (Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø±Ú© Ø§ØµÙ„Ø§Ø­ÛŒÙ‡) ---\n",
        "\n",
        "query_6 = \"Ú©Ø¯ Ø±Ø´ØªÙ‡ Ù…Ø­Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø±Ø´ØªÙ‡ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ± - Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú©Ø¯Ø§Ù…Ù†Ø¯ØŸ\"\n",
        "print(f\"[Ø´Ù…Ø§]: {query_6}\")\n",
        "answer_6 = ask_robot(query_6)\n",
        "print(f\"\\n[Ø±Ø¨Ø§Øª]:\\n{answer_6}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "query_7 = \"Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ØµÙ„Ø§Ø­ÛŒÙ‡ØŒ ØªØ§Ø±ÛŒØ® Ø¯Ù‚ÛŒÙ‚ Ø¨Ø±Ø±Ø³ÛŒ Ø³ÙˆØ§Ø¨Ù‚ Ø¹Ù„Ù…ÛŒ Ùˆ Ù…ØµØ§Ø­Ø¨Ù‡ Ú†Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø§Ø³ØªØŸ\"\n",
        "print(f\"[Ø´Ù…Ø§]: {query_7}\")\n",
        "answer_7 = ask_robot(query_7)\n",
        "print(f\"\\n[Ø±Ø¨Ø§Øª]:\\n{answer_7}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# --- Ø¯Ø³ØªÙ‡ Û´: Ø³ÙˆØ§Ù„Ø§Øª Ú©Ù†ØªØ±Ù„ÛŒ (Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø§ÛŒÙ…Ù†ÛŒ Ø±Ø¨Ø§Øª) ---\n",
        "\n",
        "query_8 = \"Ø§Ø³Ù… Ù…Ù† Ú†ÛŒØ³ØªØŸ\"\n",
        "print(f\"[Ø´Ù…Ø§]: {query_8}\")\n",
        "answer_8 = ask_robot(query_8)\n",
        "print(f\"\\n[Ø±Ø¨Ø§Øª]:\\n{answer_8}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "query_9 = \"Ù¾Ø§ÛŒØªØ®Øª Ø§ÛŒØ±Ø§Ù† Ú©Ø¬Ø§Ø³ØªØŸ\"\n",
        "print(f\"[Ø´Ù…Ø§]: {query_9}\")\n",
        "answer_9 = ask_robot(query_9)\n",
        "print(f\"\\n[Ø±Ø¨Ø§Øª]:\\n{answer_9}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "\n",
        "print(\"--- ğŸ ØªØ³Øª Ø±Ø¨Ø§Øª ØªÙ…Ø§Ù… Ø´Ø¯ ğŸ ---\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}